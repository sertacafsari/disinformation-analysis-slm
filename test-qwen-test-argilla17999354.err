Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
wandb: Appending key for api.wandb.ai to your netrc file: /home2/s5239885/.netrc
wandb: Currently logged in as: sbafsari-rug (sbafsari-rug-university-of-groningen) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /scratch/s5239885/disinformation-analysis-slm/wandb/run-20250620_153316-t9zfi75e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run argilla-qwen-test-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/sbafsari-rug-university-of-groningen/disinformation-slm
wandb: üöÄ View run at https://wandb.ai/sbafsari-rug-university-of-groningen/disinformation-slm/runs/t9zfi75e
Testing:   0%|          | 0/281 [00:00<?, ?it/s]Testing:   0%|          | 1/281 [00:24<1:55:40, 24.79s/it]Testing:   1%|          | 2/281 [00:31<1:04:29, 13.87s/it]Testing:   1%|          | 3/281 [00:33<39:52,  8.61s/it]  Testing:   1%|‚ñè         | 4/281 [00:36<30:09,  6.53s/it]Testing:   2%|‚ñè         | 5/281 [00:40<25:05,  5.46s/it]Testing:   2%|‚ñè         | 6/281 [00:43<21:22,  4.66s/it]Testing:   2%|‚ñè         | 7/281 [00:46<18:36,  4.08s/it]Testing:   3%|‚ñé         | 8/281 [00:49<17:05,  3.76s/it]Testing:   3%|‚ñé         | 9/281 [00:52<15:44,  3.47s/it]Testing:   4%|‚ñé         | 10/281 [00:57<18:52,  4.18s/it]Testing:   4%|‚ñç         | 11/281 [01:00<16:46,  3.73s/it]Testing:   4%|‚ñç         | 12/281 [01:03<14:54,  3.33s/it]Testing:   5%|‚ñç         | 13/281 [01:10<20:21,  4.56s/it]Testing:   5%|‚ñç         | 14/281 [01:13<17:59,  4.04s/it]Testing:   5%|‚ñå         | 15/281 [01:16<16:55,  3.82s/it]Testing:   6%|‚ñå         | 16/281 [01:19<15:23,  3.49s/it]Testing:   6%|‚ñå         | 17/281 [01:21<14:01,  3.19s/it]Testing:   6%|‚ñã         | 18/281 [01:24<13:29,  3.08s/it]Testing:   7%|‚ñã         | 19/281 [01:28<14:15,  3.26s/it]Testing:   7%|‚ñã         | 20/281 [01:30<13:08,  3.02s/it]Testing:   7%|‚ñã         | 21/281 [01:33<12:27,  2.87s/it]Testing:   8%|‚ñä         | 22/281 [01:36<12:34,  2.91s/it]Testing:   8%|‚ñä         | 23/281 [01:40<14:24,  3.35s/it]Testing:   9%|‚ñä         | 24/281 [01:43<13:46,  3.22s/it]Testing:   9%|‚ñâ         | 25/281 [01:47<14:40,  3.44s/it]Testing:   9%|‚ñâ         | 26/281 [01:55<20:28,  4.82s/it]Testing:  10%|‚ñâ         | 27/281 [01:58<18:30,  4.37s/it]Testing:  10%|‚ñâ         | 28/281 [02:02<17:38,  4.18s/it]Testing:  10%|‚ñà         | 29/281 [02:05<15:50,  3.77s/it]Testing:  11%|‚ñà         | 30/281 [02:14<22:21,  5.35s/it]Testing:  11%|‚ñà         | 31/281 [02:17<18:54,  4.54s/it]Testing:  11%|‚ñà‚ñè        | 32/281 [02:20<16:51,  4.06s/it]Testing:  12%|‚ñà‚ñè        | 33/281 [02:22<14:50,  3.59s/it]Testing:  12%|‚ñà‚ñè        | 34/281 [02:26<14:38,  3.56s/it]Testing:  12%|‚ñà‚ñè        | 35/281 [02:32<17:40,  4.31s/it]Testing:  13%|‚ñà‚ñé        | 36/281 [02:35<15:52,  3.89s/it]Testing:  13%|‚ñà‚ñé        | 37/281 [02:40<17:50,  4.39s/it]Testing:  14%|‚ñà‚ñé        | 38/281 [02:43<15:52,  3.92s/it]Testing:  14%|‚ñà‚ñç        | 39/281 [02:46<14:27,  3.59s/it]Testing:  14%|‚ñà‚ñç        | 40/281 [02:48<12:58,  3.23s/it]Testing:  15%|‚ñà‚ñç        | 41/281 [02:51<12:15,  3.07s/it]Testing:  15%|‚ñà‚ñç        | 42/281 [02:53<11:12,  2.82s/it]Testing:  15%|‚ñà‚ñå        | 43/281 [02:56<11:41,  2.95s/it]Testing:  16%|‚ñà‚ñå        | 44/281 [02:59<11:29,  2.91s/it]Testing:  16%|‚ñà‚ñå        | 45/281 [03:02<11:13,  2.85s/it]Testing:  16%|‚ñà‚ñã        | 46/281 [03:05<11:27,  2.93s/it]Testing:  17%|‚ñà‚ñã        | 47/281 [03:08<11:24,  2.93s/it]Testing:  17%|‚ñà‚ñã        | 48/281 [03:11<11:38,  3.00s/it]Testing:  17%|‚ñà‚ñã        | 49/281 [03:15<13:18,  3.44s/it]Testing:  18%|‚ñà‚ñä        | 50/281 [03:19<13:31,  3.51s/it]Testing:  18%|‚ñà‚ñä        | 51/281 [03:25<15:58,  4.17s/it]Testing:  19%|‚ñà‚ñä        | 52/281 [03:28<14:25,  3.78s/it]Testing:  19%|‚ñà‚ñâ        | 53/281 [03:32<14:35,  3.84s/it]Testing:  19%|‚ñà‚ñâ        | 54/281 [03:34<13:14,  3.50s/it]Testing:  20%|‚ñà‚ñâ        | 55/281 [03:37<12:08,  3.22s/it]Testing:  20%|‚ñà‚ñâ        | 56/281 [03:41<12:43,  3.39s/it]Testing:  20%|‚ñà‚ñà        | 57/281 [03:44<12:09,  3.26s/it]Testing:  21%|‚ñà‚ñà        | 58/281 [03:46<11:26,  3.08s/it]Testing:  21%|‚ñà‚ñà        | 59/281 [03:50<11:56,  3.23s/it]Testing:  21%|‚ñà‚ñà‚ñè       | 60/281 [03:53<11:18,  3.07s/it]Testing:  22%|‚ñà‚ñà‚ñè       | 61/281 [03:57<12:55,  3.52s/it]Testing:  22%|‚ñà‚ñà‚ñè       | 62/281 [04:01<13:20,  3.65s/it]Testing:  22%|‚ñà‚ñà‚ñè       | 63/281 [04:04<12:22,  3.41s/it]Testing:  23%|‚ñà‚ñà‚ñé       | 64/281 [04:08<12:48,  3.54s/it]Testing:  23%|‚ñà‚ñà‚ñé       | 64/281 [04:26<15:02,  4.16s/it]
Traceback (most recent call last):
  File "/scratch/s5239885/disinformation-analysis-slm/src/cross.py", line 118, in <module>
    tester.testArgilla()
  File "/scratch/s5239885/disinformation-analysis-slm/src/tester.py", line 130, in testArgilla
    output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1857, in _call_impl
    return inner()
           ^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1805, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 812, in forward
    transformer_outputs: BaseModelOutputWithPast = self.model(
                                                   ^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 463, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py", line 48, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 284, in forward
    hidden_states, self_attn_weights = self.self_attn(
                                       ^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 235, in forward
    attn_output, attn_weights = attention_interface(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/s5239885/disinformation-analysis-slm/.venv/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py", line 54, in sdpa_attention_forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 79.21 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 78.17 GiB memory in use. Of the allocated memory 72.67 GiB is allocated by PyTorch, and 4.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
